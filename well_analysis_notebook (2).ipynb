{"cells":[{"cell_type":"code","execution_count":61,"metadata":{},"outputs":[],"source":["# Import libraries\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt \n","import seaborn as sns"]},{"cell_type":"markdown","metadata":{},"source":["## **Read in CSV Files**:"]},{"cell_type":"code","execution_count":62,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>amount_tsh</th>\n","      <th>date_recorded</th>\n","      <th>funder</th>\n","      <th>gps_height</th>\n","      <th>installer</th>\n","      <th>longitude</th>\n","      <th>latitude</th>\n","      <th>wpt_name</th>\n","      <th>num_private</th>\n","      <th>...</th>\n","      <th>payment_type</th>\n","      <th>water_quality</th>\n","      <th>quality_group</th>\n","      <th>quantity</th>\n","      <th>quantity_group</th>\n","      <th>source</th>\n","      <th>source_type</th>\n","      <th>source_class</th>\n","      <th>waterpoint_type</th>\n","      <th>waterpoint_type_group</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>69572</td>\n","      <td>6000.0</td>\n","      <td>2011-03-14</td>\n","      <td>Roman</td>\n","      <td>1390</td>\n","      <td>Roman</td>\n","      <td>34.938093</td>\n","      <td>-9.856322</td>\n","      <td>none</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>annually</td>\n","      <td>soft</td>\n","      <td>good</td>\n","      <td>enough</td>\n","      <td>enough</td>\n","      <td>spring</td>\n","      <td>spring</td>\n","      <td>groundwater</td>\n","      <td>communal standpipe</td>\n","      <td>communal standpipe</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>8776</td>\n","      <td>0.0</td>\n","      <td>2013-03-06</td>\n","      <td>Grumeti</td>\n","      <td>1399</td>\n","      <td>GRUMETI</td>\n","      <td>34.698766</td>\n","      <td>-2.147466</td>\n","      <td>Zahanati</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>never pay</td>\n","      <td>soft</td>\n","      <td>good</td>\n","      <td>insufficient</td>\n","      <td>insufficient</td>\n","      <td>rainwater harvesting</td>\n","      <td>rainwater harvesting</td>\n","      <td>surface</td>\n","      <td>communal standpipe</td>\n","      <td>communal standpipe</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2 rows × 40 columns</p>\n","</div>"],"text/plain":["      id  amount_tsh date_recorded   funder  gps_height installer  longitude  \\\n","0  69572      6000.0    2011-03-14    Roman        1390     Roman  34.938093   \n","1   8776         0.0    2013-03-06  Grumeti        1399   GRUMETI  34.698766   \n","\n","   latitude  wpt_name  num_private  ... payment_type water_quality  \\\n","0 -9.856322      none            0  ...     annually          soft   \n","1 -2.147466  Zahanati            0  ...    never pay          soft   \n","\n","  quality_group      quantity  quantity_group                source  \\\n","0          good        enough          enough                spring   \n","1          good  insufficient    insufficient  rainwater harvesting   \n","\n","            source_type  source_class     waterpoint_type  \\\n","0                spring   groundwater  communal standpipe   \n","1  rainwater harvesting       surface  communal standpipe   \n","\n","  waterpoint_type_group  \n","0    communal standpipe  \n","1    communal standpipe  \n","\n","[2 rows x 40 columns]"]},"execution_count":62,"metadata":{},"output_type":"execute_result"}],"source":["train_values_df = pd.read_csv('data/training_set_values.csv')\n","train_values_df.head(2) "]},{"cell_type":"code","execution_count":63,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>amount_tsh</th>\n","      <th>date_recorded</th>\n","      <th>funder</th>\n","      <th>gps_height</th>\n","      <th>installer</th>\n","      <th>longitude</th>\n","      <th>latitude</th>\n","      <th>wpt_name</th>\n","      <th>num_private</th>\n","      <th>...</th>\n","      <th>payment_type</th>\n","      <th>water_quality</th>\n","      <th>quality_group</th>\n","      <th>quantity</th>\n","      <th>quantity_group</th>\n","      <th>source</th>\n","      <th>source_type</th>\n","      <th>source_class</th>\n","      <th>waterpoint_type</th>\n","      <th>waterpoint_type_group</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>50785</td>\n","      <td>0.0</td>\n","      <td>2013-02-04</td>\n","      <td>Dmdd</td>\n","      <td>1996</td>\n","      <td>DMDD</td>\n","      <td>35.290799</td>\n","      <td>-4.059696</td>\n","      <td>Dinamu Secondary School</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>never pay</td>\n","      <td>soft</td>\n","      <td>good</td>\n","      <td>seasonal</td>\n","      <td>seasonal</td>\n","      <td>rainwater harvesting</td>\n","      <td>rainwater harvesting</td>\n","      <td>surface</td>\n","      <td>other</td>\n","      <td>other</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>51630</td>\n","      <td>0.0</td>\n","      <td>2013-02-04</td>\n","      <td>Government Of Tanzania</td>\n","      <td>1569</td>\n","      <td>DWE</td>\n","      <td>36.656709</td>\n","      <td>-3.309214</td>\n","      <td>Kimnyak</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>never pay</td>\n","      <td>soft</td>\n","      <td>good</td>\n","      <td>insufficient</td>\n","      <td>insufficient</td>\n","      <td>spring</td>\n","      <td>spring</td>\n","      <td>groundwater</td>\n","      <td>communal standpipe</td>\n","      <td>communal standpipe</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2 rows × 40 columns</p>\n","</div>"],"text/plain":["      id  amount_tsh date_recorded                  funder  gps_height  \\\n","0  50785         0.0    2013-02-04                    Dmdd        1996   \n","1  51630         0.0    2013-02-04  Government Of Tanzania        1569   \n","\n","  installer  longitude  latitude                 wpt_name  num_private  ...  \\\n","0      DMDD  35.290799 -4.059696  Dinamu Secondary School            0  ...   \n","1       DWE  36.656709 -3.309214                  Kimnyak            0  ...   \n","\n","  payment_type water_quality quality_group      quantity  quantity_group  \\\n","0    never pay          soft          good      seasonal        seasonal   \n","1    never pay          soft          good  insufficient    insufficient   \n","\n","                 source           source_type  source_class  \\\n","0  rainwater harvesting  rainwater harvesting       surface   \n","1                spring                spring   groundwater   \n","\n","      waterpoint_type waterpoint_type_group  \n","0               other                 other  \n","1  communal standpipe    communal standpipe  \n","\n","[2 rows x 40 columns]"]},"execution_count":63,"metadata":{},"output_type":"execute_result"}],"source":["test_values_df = pd.read_csv('data/test_set_values.csv')\n","test_values_df.head(2)"]},{"cell_type":"code","execution_count":64,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>status_group</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>50785</td>\n","      <td>predicted label</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>51630</td>\n","      <td>predicted label</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>17168</td>\n","      <td>predicted label</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>45559</td>\n","      <td>predicted label</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>49871</td>\n","      <td>predicted label</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      id     status_group\n","0  50785  predicted label\n","1  51630  predicted label\n","2  17168  predicted label\n","3  45559  predicted label\n","4  49871  predicted label"]},"execution_count":64,"metadata":{},"output_type":"execute_result"}],"source":["submission_format_df = pd.read_csv('data/submission_format.csv')\n","submission_format_df.head()"]},{"cell_type":"code","execution_count":65,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>status_group</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>69572</td>\n","      <td>functional</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>8776</td>\n","      <td>functional</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>34310</td>\n","      <td>functional</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>67743</td>\n","      <td>non functional</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>19728</td>\n","      <td>functional</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      id    status_group\n","0  69572      functional\n","1   8776      functional\n","2  34310      functional\n","3  67743  non functional\n","4  19728      functional"]},"execution_count":65,"metadata":{},"output_type":"execute_result"}],"source":["train_labels_df = pd.read_csv('data/training_set_labels.csv')\n","train_labels_df.head()"]},{"cell_type":"markdown","metadata":{},"source":["## **Merging Dataframes Above**"]},{"cell_type":"code","execution_count":66,"metadata":{},"outputs":[],"source":["# merging train_values_df & train_labels_df\n","train_values_df = pd.merge(train_values_df, train_labels_df, on='id', how='left')\n","# merging test_values_df & submission_format_df\n","test_values_df = pd.merge(test_values_df, submission_format_df, on='id', how='left')"]},{"cell_type":"markdown","metadata":{},"source":["---"]},{"cell_type":"markdown","metadata":{},"source":["## **EDA**"]},{"cell_type":"code","execution_count":67,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["train_values_df columns: \n","['id', 'amount_tsh', 'date_recorded', 'funder', 'gps_height', 'installer', 'longitude', 'latitude', 'wpt_name', 'num_private', 'basin', 'subvillage', 'region', 'region_code', 'district_code', 'lga', 'ward', 'population', 'public_meeting', 'recorded_by', 'scheme_management', 'scheme_name', 'permit', 'construction_year', 'extraction_type', 'extraction_type_group', 'extraction_type_class', 'management', 'management_group', 'payment', 'payment_type', 'water_quality', 'quality_group', 'quantity', 'quantity_group', 'source', 'source_type', 'source_class', 'waterpoint_type', 'waterpoint_type_group', 'status_group']\n","(59400, 41)\n","\n","test_values_df columns: \n","['id', 'amount_tsh', 'date_recorded', 'funder', 'gps_height', 'installer', 'longitude', 'latitude', 'wpt_name', 'num_private', 'basin', 'subvillage', 'region', 'region_code', 'district_code', 'lga', 'ward', 'population', 'public_meeting', 'recorded_by', 'scheme_management', 'scheme_name', 'permit', 'construction_year', 'extraction_type', 'extraction_type_group', 'extraction_type_class', 'management', 'management_group', 'payment', 'payment_type', 'water_quality', 'quality_group', 'quantity', 'quantity_group', 'source', 'source_type', 'source_class', 'waterpoint_type', 'waterpoint_type_group', 'status_group']\n","(14850, 41)\n","\n","submission_format_df columns: \n","['id', 'status_group']\n","(14850, 2)\n","\n","train_labels_df columns: \n","['id', 'status_group']\n","(59400, 2)\n","\n"]}],"source":["print(f'train_values_df columns: \\n{list(train_values_df.columns)}\\n{train_values_df.shape}\\n')\n","print(f'test_values_df columns: \\n{list(test_values_df.columns)}\\n{test_values_df.shape}\\n')\n","print(f'submission_format_df columns: \\n{list(submission_format_df.columns)}\\n{submission_format_df.shape}\\n')\n","print(f'train_labels_df columns: \\n{list(train_labels_df.columns)}\\n{train_labels_df.shape}\\n')"]},{"cell_type":"markdown","metadata":{},"source":["---"]},{"cell_type":"markdown","metadata":{},"source":["## **Identify Missing Values**"]},{"cell_type":"markdown","metadata":{},"source":["#### (7) columns with missing values in **train_values_df**:"]},{"cell_type":"code","execution_count":68,"metadata":{},"outputs":[{"data":{"text/plain":["scheme_name          28166\n","scheme_management     3877\n","installer             3655\n","funder                3635\n","public_meeting        3334\n","permit                3056\n","subvillage             371\n","dtype: int64"]},"execution_count":68,"metadata":{},"output_type":"execute_result"}],"source":["train_values_df.isna().sum().sort_values(ascending=False).head(7)"]},{"cell_type":"markdown","metadata":{},"source":["#### (7) columns with missing values in **test_values_df**:"]},{"cell_type":"code","execution_count":69,"metadata":{},"outputs":[{"data":{"text/plain":["scheme_name          7092\n","scheme_management     969\n","installer             877\n","funder                869\n","public_meeting        821\n","permit                737\n","subvillage             99\n","dtype: int64"]},"execution_count":69,"metadata":{},"output_type":"execute_result"}],"source":["test_values_df.isna().sum().sort_values(ascending=False).head(7)"]},{"cell_type":"markdown","metadata":{},"source":["#### No values missing in **submission_format_df**:"]},{"cell_type":"code","execution_count":70,"metadata":{},"outputs":[{"data":{"text/plain":["id              0\n","status_group    0\n","dtype: int64"]},"execution_count":70,"metadata":{},"output_type":"execute_result"}],"source":["submission_format_df.isna().sum().sort_values(ascending=False)"]},{"cell_type":"markdown","metadata":{},"source":["#### No values missing in **train_labels_df**:"]},{"cell_type":"code","execution_count":71,"metadata":{},"outputs":[{"data":{"text/plain":["id              0\n","status_group    0\n","dtype: int64"]},"execution_count":71,"metadata":{},"output_type":"execute_result"}],"source":["train_labels_df.isna().sum().sort_values(ascending=False)"]},{"cell_type":"markdown","metadata":{},"source":["---"]},{"cell_type":"markdown","metadata":{},"source":["## **Data Limitations & Cleaning**"]},{"cell_type":"markdown","metadata":{},"source":["What we do to **train_values_df** we will do to **test_values_df**:\n","1. **Dropping Columns**:\n","- For example, **'scheme_name'** is missing 28,166 values out of 59,400 in train_values_df. As a result, we will drop this column and others we wont need.\n","2. **Dropping rows with missing values**:\n","- For rows with a few missing values, we will drop the rows so we can preserve the columns.\n","3. **Data Type Conversion**:\n","- The 'date_recorded' column was the only column that needed to be changes to datetime\n","4. **Renaming Columns**:\n","- Many of the columns have names that are confusing or dont represent the data. These have been changed."]},{"cell_type":"code","execution_count":72,"metadata":{},"outputs":[],"source":["\n","# Dropping unneeded columns\n","dropped_columns = ['scheme_name', 'num_private', 'region_code', 'district_code',\n","                   'public_meeting', 'recorded_by', 'extraction_type',\n","                   'extraction_type_group', 'management', 'payment_type',\n","                   'water_quality', 'quantity_group', 'source_type', 'waterpoint_type' ,'payment_type' , 'funder' , 'subvillage', 'lga', 'construction_year', 'date_recorded',\n","                   'scheme_management', 'installer', 'id', 'population', 'longitude', 'latitude', 'waterpoint_type_group'\n","                   ]\n","train_values_df = train_values_df.drop(columns=dropped_columns)\n","test_values_df = test_values_df.drop(columns=dropped_columns)\n","\n","\n","# Dropping rows with missing values\n","dropped_rows = ['permit'\n","                ]\n","train_values_df.dropna(subset=dropped_rows, inplace=True)\n","test_values_df.dropna(subset=dropped_rows, inplace=True)\n","\n","# Renaming Columns\n","renamed_col = {'amount_tsh': 'total_static_head(ft)', 'gps_height': 'height',\n","               'wpt_name': 'waterpoint_name', 'basin': 'basin_location',\n","                'permit': 'permit_approved',\n","               'extraction_type_class': 'extraction_method',\n","               'management_group': 'management_type',\n","                'quality_group': 'quality_of_water',\n","               'quantity': 'quantity_of_water', 'source': 'water_source'\n","               }\n","train_values_df = train_values_df.rename(columns=renamed_col)\n","test_values_df = test_values_df.rename(columns=renamed_col)\n"]},{"cell_type":"markdown","metadata":{},"source":["---"]},{"cell_type":"code","execution_count":73,"metadata":{},"outputs":[{"data":{"text/plain":["functional                 30586\n","non functional             21741\n","functional needs repair     4017\n","Name: status_group, dtype: int64"]},"execution_count":73,"metadata":{},"output_type":"execute_result"}],"source":["train_values_df['status_group'].value_counts()"]},{"cell_type":"code","execution_count":74,"metadata":{},"outputs":[{"data":{"text/plain":["functional        34603\n","non functional    21741\n","Name: status_group, dtype: int64"]},"execution_count":74,"metadata":{},"output_type":"execute_result"}],"source":["# Adding Functional needs repairs values to Functional\n","train_values_df[train_values_df['status_group'] == 'functional needs repair'] = \"functional\"\n","train_values_df['status_group'].value_counts()"]},{"cell_type":"markdown","metadata":{},"source":["## **Sorting Dataframes**"]},{"cell_type":"code","execution_count":75,"metadata":{},"outputs":[{"data":{"text/plain":["Index(['total_static_head(ft)', 'height', 'waterpoint_name', 'basin_location',\n","       'region', 'ward', 'permit_approved', 'extraction_method'],\n","      dtype='object')"]},"execution_count":75,"metadata":{},"output_type":"execute_result"}],"source":["train_values_df.columns[0:8]\n"]},{"cell_type":"code","execution_count":76,"metadata":{},"outputs":[],"source":["#if unknown makes up less than 1%, drop unknown rows from our table \n","def drop_unknown(df, column):\n","    counts = df[column].value_counts(normalize=True)\n","    if 'unknown' in counts.index and counts['unknown'] < 0.01:\n","        df.drop(df[df[column] == 'unknown'].index, inplace=True)\n","\n","#loop through columns to drop unknowns\n","for column in train_values_df.columns: \n","    drop_unknown(train_values_df, column)"]},{"cell_type":"markdown","metadata":{},"source":["## Modeling"]},{"cell_type":"markdown","metadata":{},"source":["## Decision Tree Modeling\n"]},{"cell_type":"code","execution_count":77,"metadata":{},"outputs":[],"source":["from sklearn.tree import DecisionTreeClassifier\n"]},{"cell_type":"code","execution_count":78,"metadata":{},"outputs":[],"source":["train_values_df['status_group'] = train_values_df['status_group'].map({'functional': 1, 'non functional': 0})"]},{"cell_type":"code","execution_count":79,"metadata":{},"outputs":[{"data":{"text/plain":["1    34143\n","0    21022\n","Name: status_group, dtype: int64"]},"execution_count":79,"metadata":{},"output_type":"execute_result"}],"source":["train_values_df['status_group'].value_counts()"]},{"cell_type":"code","execution_count":80,"metadata":{},"outputs":[{"ename":"TypeError","evalue":"Encoders require their input to be uniformly strings or numbers. Got ['float', 'str']","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)","File \u001b[1;32mc:\\Users\\NCG\\anaconda3Flatiron\\lib\\site-packages\\sklearn\\utils\\_encode.py:173\u001b[0m, in \u001b[0;36m_unique_python\u001b[1;34m(values, return_inverse, return_counts)\u001b[0m\n\u001b[0;32m    171\u001b[0m uniques_set, missing_values \u001b[39m=\u001b[39m _extract_missing(uniques_set)\n\u001b[1;32m--> 173\u001b[0m uniques \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39;49m(uniques_set)\n\u001b[0;32m    174\u001b[0m uniques\u001b[39m.\u001b[39mextend(missing_values\u001b[39m.\u001b[39mto_list())\n","\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'float'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[80], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m X_cats \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mselect_dtypes(include\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m ohe \u001b[39m=\u001b[39m OneHotEncoder(drop\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfirst\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m ohe\u001b[39m.\u001b[39;49mfit(X_cats)\n\u001b[0;32m      9\u001b[0m X_cats_encoded \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(ohe\u001b[39m.\u001b[39mtransform(X_cats)\u001b[39m.\u001b[39mtodense(), columns\u001b[39m=\u001b[39mohe\u001b[39m.\u001b[39mget_feature_names_out())\n","File \u001b[1;32mc:\\Users\\NCG\\anaconda3Flatiron\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:838\u001b[0m, in \u001b[0;36mOneHotEncoder.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    834\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msparse_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msparse\n\u001b[0;32m    836\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_infrequent_enabled()\n\u001b[1;32m--> 838\u001b[0m fit_results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(\n\u001b[0;32m    839\u001b[0m     X,\n\u001b[0;32m    840\u001b[0m     handle_unknown\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle_unknown,\n\u001b[0;32m    841\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    842\u001b[0m     return_counts\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_infrequent_enabled,\n\u001b[0;32m    843\u001b[0m )\n\u001b[0;32m    844\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_infrequent_enabled:\n\u001b[0;32m    845\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_infrequent_category_mapping(\n\u001b[0;32m    846\u001b[0m         fit_results[\u001b[39m\"\u001b[39m\u001b[39mn_samples\u001b[39m\u001b[39m\"\u001b[39m], fit_results[\u001b[39m\"\u001b[39m\u001b[39mcategory_counts\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    847\u001b[0m     )\n","File \u001b[1;32mc:\\Users\\NCG\\anaconda3Flatiron\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:93\u001b[0m, in \u001b[0;36m_BaseEncoder._fit\u001b[1;34m(self, X, handle_unknown, force_all_finite, return_counts)\u001b[0m\n\u001b[0;32m     90\u001b[0m Xi \u001b[39m=\u001b[39m X_list[i]\n\u001b[0;32m     92\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcategories \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m---> 93\u001b[0m     result \u001b[39m=\u001b[39m _unique(Xi, return_counts\u001b[39m=\u001b[39;49mreturn_counts)\n\u001b[0;32m     94\u001b[0m     \u001b[39mif\u001b[39;00m return_counts:\n\u001b[0;32m     95\u001b[0m         cats, counts \u001b[39m=\u001b[39m result\n","File \u001b[1;32mc:\\Users\\NCG\\anaconda3Flatiron\\lib\\site-packages\\sklearn\\utils\\_encode.py:41\u001b[0m, in \u001b[0;36m_unique\u001b[1;34m(values, return_inverse, return_counts)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39m\"\"\"Helper function to find unique values with support for python objects.\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \n\u001b[0;32m     12\u001b[0m \u001b[39mUses pure python method for object dtype, and numpy method for\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[39m    array. Only provided if `return_counts` is True.\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[39mif\u001b[39;00m values\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m \u001b[39mobject\u001b[39m:\n\u001b[1;32m---> 41\u001b[0m     \u001b[39mreturn\u001b[39;00m _unique_python(\n\u001b[0;32m     42\u001b[0m         values, return_inverse\u001b[39m=\u001b[39;49mreturn_inverse, return_counts\u001b[39m=\u001b[39;49mreturn_counts\n\u001b[0;32m     43\u001b[0m     )\n\u001b[0;32m     44\u001b[0m \u001b[39m# numerical\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[39mreturn\u001b[39;00m _unique_np(\n\u001b[0;32m     46\u001b[0m     values, return_inverse\u001b[39m=\u001b[39mreturn_inverse, return_counts\u001b[39m=\u001b[39mreturn_counts\n\u001b[0;32m     47\u001b[0m )\n","File \u001b[1;32mc:\\Users\\NCG\\anaconda3Flatiron\\lib\\site-packages\\sklearn\\utils\\_encode.py:178\u001b[0m, in \u001b[0;36m_unique_python\u001b[1;34m(values, return_inverse, return_counts)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    177\u001b[0m     types \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(t\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mset\u001b[39m(\u001b[39mtype\u001b[39m(v) \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m values))\n\u001b[1;32m--> 178\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    179\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mEncoders require their input to be uniformly \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    180\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstrings or numbers. Got \u001b[39m\u001b[39m{\u001b[39;00mtypes\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    181\u001b[0m     )\n\u001b[0;32m    182\u001b[0m ret \u001b[39m=\u001b[39m (uniques,)\n\u001b[0;32m    184\u001b[0m \u001b[39mif\u001b[39;00m return_inverse:\n","\u001b[1;31mTypeError\u001b[0m: Encoders require their input to be uniformly strings or numbers. Got ['float', 'str']"]}],"source":["from sklearn.preprocessing import OneHotEncoder\n","X = train_values_df.drop('status_group', axis=1)\n","y = train_values_df['status_group']\n","\n","X_cats = X.select_dtypes(include='object')\n","\n","ohe = OneHotEncoder(drop='first')\n","ohe.fit(X_cats)\n","X_cats_encoded = pd.DataFrame(ohe.transform(X_cats).todense(), columns=ohe.get_feature_names_out())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X_cats_encoded.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#concat with numerical columns \n","X_num = X.select_dtypes(exclude='object')\n","X_cats_encoded = X_cats_encoded.reset_index(drop=True)\n","X_num = X_num.reset_index(drop=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","X_processed = pd.concat([X_num, X_cats_encoded], axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X_processed.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#perform train-test split\n","X = X_processed\n","y = train_values_df['status_group']\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#fit decision tree\n","dt = DecisionTreeClassifier(random_state=42)\n","dt.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#predict from X_test\n","y_preds = dt.predict(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n","\n","ConfusionMatrixDisplay.from_estimator(dt, X_test, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import recall_score, accuracy_score, precision_score, f1_score\n","\n","recall = recall_score(y_test, y_preds)\n","accuracy = accuracy_score(y_test, y_preds)\n","f1 = f1_score(y_test, y_preds)\n","\n","print(f'recall: {recall}')\n","print(f'accuracy: {accuracy}')\n","print(f'f1: {f1}')"]}],"metadata":{"kernelspec":{"display_name":"learn-env","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
